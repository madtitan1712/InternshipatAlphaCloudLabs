# Internship at AlphaCloudLabs
This github repo contains my work done in a 10 day internship at Alphacloud labs, Chennai.

# Day 1:
  
  Started today. 

  - Refreshed Python
  - scraping
  - An small Scraper that scrapes text from an targeted Website
  - Used BS4 and the requests Library in python to create a program that can scrape websites

# Day 2:

  Learnt:
  - Beautiful soup
  - Requests library
  - Selenium
  - lxml
  - Scrapy
  Created a new python script which combed through any wikipedia page and collected resources from it in the form of text and Images

# Day 3:

  Selenium Webdriver:
  
  An API, that can interact and control browsers.

  Selenium can manipulate both browsers and automate them. This makes them an ideal choice for testing websites. 
  All elements can be found or be manipulated using their attributes like
    - Xpath
    - ID
    - Name
    - Class_name
    - CSS ID
  
  Xpath is something that is used to locate objects on the DOM. Here everything is like an tree based structure, so you can call the children and parent objects easily. 
  
  Reference for Xpath: [W3Schools.com](https://www.w3schools.com/xml/xpath_syntax.asp)

# Day 4:
  
Wrote 4 scripts to:
  - Extract the F1 driver stadings from the Website
  - Extract the F1 Race Results from a previous season
  - Scrape the top 250 movies list from IMDB
  - Scrape Instagram post images.

Learning objectives:
  - CSV module
  - Image Scraping basics

Learnt to scrape the main post images from Instagram. If the image is a carousel, then the script needs how many images are there in the carousel in order to scrape it

# Day 5:

Numpy Basics:
  - How to initialize a numpy array
  - basic functions on numpy
  - mathematical functions on numpy
  - append/sort/insert/delete
Image Scraping:
  - Scraped a F1 related Website
  - Scraped a Premier League website to scour images
   
# Day 6:

Writing a script to scrape data from google on sports schedules.

This program uses selenium to target webelements and extract information from them.
  
Numpy Basics:
  - Open Google and search for the given sport nfl 
  - then navigate to the table with the schedule
  - then click on it and scrape the team names and their dates

# Day 7:

The script of scraping the data from google on sports schedules was improved.

Added Features:
  - Can open every single match data and collect the venue of the match
  - Used Selenium to automate the feature
  - Automated by clicking on each element and then opens the next element

# Day 8:


  

